# 6. PTT C_Chat板爬蟲

###### tags: `2022資工營`

學完怎麼用BeautifulSoup解析HTML後，接著就來實際找個網站來現學現賣一下!

我選PTT當作例子，為什麼要選PTT呢? 因為PTT是很多人使用而且算是相對好爬的網站，很適合當成第一次練習爬蟲的網站。

[PTT C_Chat板網址](https://www.ptt.cc/bbs/C_Chat/index.html)

我們的目標很簡單，就是取得PTT C_Chat板上的**文章標題**(紅框圈起來的部分)。

![](https://i.imgur.com/cDhHU60.png)


## 文章標題

首先，我們對文章標題**右鍵>>檢查**，右邊會跳出開發人員介面顯示文章標題在原始碼中的位置。

稍微觀察一下，我們會發現所有的文章標題都在`class="title"`的`<div>`中。

![](https://i.imgur.com/6ESgYZM.png)

所以很簡單，程式碼就這樣寫：

```python
import requests
from bs4 import BeautifulSoup

url = "https://www.ptt.cc/bbs/C_Chat/index.html"

response = requests.get(url) # 取得C_Chat的HTML原始碼
root = BeautifulSoup(response.text, "html.parser")  # 解析原始碼

links = root.find_all("div", class_="title")    # 文章標題
for link in links:  # 用for迴圈一次迭代一個元素
    print(link.text.strip()) # strip()用來刪除文字前面和後面多餘的空白
```
執行結果：

![](https://i.imgur.com/h0wV73r.png)


## 小試身手1

現在請大家舉一反三，取得每篇文章的**作者名稱**(紅框圈起來的部分)。

![](https://i.imgur.com/5wFRoFL.png)


## 自動換頁

現在雖然可以抓下文章清單中的標題了，但只有第一頁的文章而已，要怎麼樣才能抓其他頁的文章呢??

想一下，我們想要看上一頁時，會做什麼事?

還不簡單! 當然就是按 "上頁" 按鈕阿!

對上方導覽列的 "上頁" 按鈕**右鍵>>檢查**，上一頁的連結就在`string="‹ 上頁"`的`<a>`中。

![](https://i.imgur.com/Grhz9gh.png)

可是我們也發現了，連結的**href屬性**並不是完整的網址，只有網域後面的部分而已。

但也沒關係，因為網域部分是固定的所以我們自己加上去就好了。

每次更新url變數，然後用for迴圈想抓幾頁就抓幾頁!

```python
import requests
from bs4 import BeautifulSoup

url = "https://www.ptt.cc/bbs/C_Chat/index.html"    # 第一頁

for i in range(10):
    print(f"第{i+1}頁：")   # 現在到第幾頁

    response = requests.get(url) # 取得C_Chat的HTML原始碼
    root = BeautifulSoup(response.text, "html.parser")  # 解析原始碼

    links = root.find_all("div", class_="title")    # 文章標題
    for link in links:
        print(link.text.strip()) # strip()用來刪除文字前面和後面多餘的空白

    url = "https://www.ptt.cc/" + root.find("a", string="‹ 上頁")["href"] # 換頁
```


## 儲存csv檔

目前都只是將抓到的資料印在小黑窗上，如果之後要用到這些資料做後續分析的話，就很不方便了，所以我們要將資料轉成csv格式並存在電腦中。

逗號分隔值 (Comma-Separated Values，CSV)，是一種常見的資料儲存方式，其換行代表一個row，並用逗號區分column。

![](https://i.imgur.com/CaS2BFP.png)

我們抓取每篇文章的**標題**和**作者**，並存成csv檔。

因為這次要一次取得同一篇文章的標題和作者，所以程式碼要稍微做修改...。

回到PTT，我們可以發現每篇文章都是包在`class="r-ent"`的`<div>`中，**因此我們要先找到所有的文章，在找出每篇文章底下的標題和作者就好了!**

![](https://i.imgur.com/yevNBqK.png)

```python
articles = root.find_all("div", class_="r-ent")    # 所有文章
for article in articles:
    title = article.find("div", class_="title").text.strip()    # 文章標題
    author = article.find("div", class_="author").text      # 文章作者

    print(title, author)
```

引用Python的csv套件，並開啟一個新的檔案，檔名為"ptt.csv"，`newline=""`才不會多換一行，記得編碼改成"utf-8-sig"，不然會出現亂碼。

接著建立一個csv writer物件，使用該物件的`writerow()`函數寫入資料。

程式執行完後，在資料夾中就會多一個"ptt.csv"檔案啦，打開來看看是不是資料都已經在裡面了!

```python
import requests
from bs4 import BeautifulSoup
import csv

url = "https://www.ptt.cc/bbs/C_Chat/index.html"    # 第一頁

# 開啟csv檔案
with open("ptt.csv", "w", newline="", encoding="utf-8-sig") as csvfile:
    # 建立 CSV 檔寫入器
    writer = csv.writer(csvfile)
    # 寫入欄位名稱
    writer.writerow(["標題", "作者"])

    for i in range(10):
        print(f"第{i+1}頁：")
        response = requests.get(url) # 取得C_Chat的HTML原始碼
        root = BeautifulSoup(response.text, "html.parser")  # 解析原始碼

        articles = root.find_all("div", class_="r-ent")    # 所有文章
        for article in articles:
            title = article.find("div", class_="title").text.strip()    # 文章標題
            author = article.find("div", class_="author").text      # 文章作者

            print(title, author)

            writer.writerow([title, author])    # 寫入一行資料

        url = "https://www.ptt.cc/"+root.find("a", string="‹ 上頁")["href"] # 換頁
```

![](https://i.imgur.com/bWP0Ig2.png)


## 小試身手2

根據上一張的程式碼，加上一些新的程式，在csv檔多儲存一個**發文時間**的欄位。

![](https://i.imgur.com/xwcvhY4.png)


## 小試身手3

從PTT中挑一個喜歡的分類看板出來，看看能不能做到一樣的事情~

[PTT熱門分類看板](https://www.ptt.cc/bbs/index.html)
